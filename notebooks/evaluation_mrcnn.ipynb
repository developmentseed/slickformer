{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceee29e2-0f8f-49ff-83af-bd0fb4624cd5",
   "metadata": {},
   "source": [
    "### Evaluating the Mask R-CNN Torchscript model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7a5637-7f0b-4171-bef0-4daf88508b67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from pycocotools import mask as maskUtils\n",
    "from matplotlib.patches import Patch\n",
    "import torch\n",
    "import torchvision\n",
    "import torchdata\n",
    "from ceruleanml import plot, data_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0e9953-576a-4235-ae5f-eaaba2b728e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"/slickformer/data/models/2023_02_18_00_38_07_4cls_rn152_pr512_px1024_1440min_maskrcnn_scripting_cpu_model.pt\"\n",
    "scripted_model = torch.jit.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d854de82-8773-47ac-b0d1-70bdd0bfdb22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f5adb9-3bb6-4792-857b-bfc031082964",
   "metadata": {},
   "source": [
    "### Grabbing a test image to inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2156184c-8928-4367-99c1-c0821ab48e32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_scene = \"S1A_IW_GRDH_1SDV_20210220T174437_20210220T174502_036677_044F60_51BC\" # lots of slicks\n",
    "\n",
    "data_dir = Path(\"../data/partitions/test_tiles_context_0/\")\n",
    "\n",
    "l = data_dir/\"tiled_images\"\n",
    "\n",
    "imgs = list(l.glob(\"*\"))\n",
    "\n",
    "test_path = [i for i in imgs if test_scene in i.as_posix()][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a68ae-49b6-4ea6-9e2a-f6b46a93b47d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load annotations and decode them to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc59302-9546-47e8-b08d-990b2edc2dca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(data_dir/\"instances_CeruleanCOCO.json\", 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "mask_cat_ids, mask_arrs = data_pipeline.decode_masks(test_scene, annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b630d84-6705-4cf7-9404-d2771a9cde54",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Create a new image to draw on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b24d01-9889-49e1-8374-81dbe2536f2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_im_pil_channels = Image.open(test_path).split()\n",
    "\n",
    "test_im_pil_vv = test_im_pil_channels[0]\n",
    "plot.plot_scene_annotations(test_path, mask_arrs, mask_cat_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a5ce25-fd15-4108-8f1e-c144b9d9f72e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_pipe = torchdata.datapipes.iter.IterableWrapper(iterable=[annotations])\n",
    "labels_pipe = torchdata.datapipes.iter.IterableWrapper(iterable=[annotations])\n",
    "source = (\n",
    "    source_pipe.get_scene_paths(\"/slickformer/data/partitions/test_tiles_context_0/\")  # get source items from the collection\n",
    "    .read_tiff()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54f2fc5-43a0-4b61-973f-7c7252906c21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = (\n",
    "    labels_pipe.decode_masks()\n",
    "    .map(lambda x: x[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42914504-2453-499b-9ded-ac57d6dc6413",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channel_first = lambda x: (np.moveaxis(x['image'],2,0), x['masks']) # needs to happen after pil crop\n",
    "normalize = lambda x: (x[0]/255, x[1]) # faster if applied post pil crop by about 1 second\n",
    "to_tensor = lambda x: (torch.Tensor(x[0]), x[1]) # we only need the mrcnn model as a cpu tensor for inference, then compute eval w numpy on cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faed4ffe-cebd-4270-8777-bc794456dac8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trn_dp, val_dp, tst_dp = (\n",
    "    source.zip(labels)\n",
    "    .random_crop_mask_if_exists(2000,2000)\n",
    "    .map(channel_first)\n",
    "    .map(normalize)\n",
    "    .map(to_tensor)\n",
    "    # .shuffle()\n",
    "    .random_split(\n",
    "        total_length=len(source),\n",
    "        weights={\"trn\": 0.7, \"val\": 0.2, \"tst\": 0.1},\n",
    "        seed=0,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638d87a5-d46e-4e2b-862c-04adaa72af22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "x=next(iter(trn_dp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d307a0c4-15de-4e17-a423-64e62bcebbe8",
   "metadata": {},
   "source": [
    "maskrcnn wants a list of 3D arrays with length of list as batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaad2a6-0c2c-489e-87de-ffb3436e8e33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate model:\n",
    "scripted_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    losses, pred_list = scripted_model([x[0]])\n",
    "pred_list[0]['masks'] = np.squeeze(pred_list[0]['masks']) # we modify this to match expected shape for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be04edb0-7a30-4eef-80cb-4b3a1a7598e6",
   "metadata": {},
   "source": [
    "pred_list details\n",
    "\n",
    "* len of pred_list is always 1 if input is 1\n",
    "* bbox coords are not normalized. \n",
    "* dict values are tensors until post processed with conf thresholding.\n",
    "* length of value list indicates how many instances detected both low and high confidence\n",
    "* Mask R-CNN mask values are not logits, they are 0 to 1 confidence probabilities. the torchscript model applies softmax unlike the fastai unet model where we do that after inference.\n",
    "* bbox coord order is xmin, ymin, xmax, ymax, the same as icevision record collection bbox format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4705520-fba2-4a4c-870b-ba637d931d31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ad71ef-e88b-446c-8e62-2716f572f2e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ceruleanml.inference import apply_conf_threshold_instances, apply_conf_threshold_masks\n",
    "bbox_conf_threshold = .5\n",
    "pred_dict = apply_conf_threshold_instances(pred_list[0], bbox_conf_threshold=bbox_conf_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca0605-ef0d-4860-a6a2-4177ffc63248",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_dict['scores']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5ef12e-d0e9-453f-a683-36dd414a8fb5",
   "metadata": {},
   "source": [
    "We can extract the first mask in the first sample's prediction and plot it by converting it to a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6964100-6558-411f-b74b-9dc9426db5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as skio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bc94cf-57b5-4967-bf1d-50ebe19d37e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skio.imshow(pred_dict['masks'][0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff00012-435f-4946-b3c1-5b876f649e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "high_conf_class_arrs = apply_conf_threshold_masks(pred_dict, mask_conf_threshold=.05, size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879dbbad-e549-4dae-9b1d-7f0ebcf9f807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "high_conf_class_arrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebb8814-3c1f-45e4-a4b2-4e18a67a7162",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot.plot_scene_annotations(x[0][0], high_conf_class_arrs, pred_dict['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6bf0de-1296-4f39-9e6e-7ce4b48608ed",
   "metadata": {},
   "source": [
    "TODO plot a histogram of confidence scores for a pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9eac06-4efc-40ea-8c6f-f91c7524ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test = pred_list[0]['masks'][0,0,:,:].detach().cpu().numpy().flatten()\n",
    "\n",
    "# scratch code\n",
    "# np.ma.masked_where(test!=0, test)\n",
    "\n",
    "# plt.hist(np.ma.masked_where(test!=0, test), bins = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2effa2b9-97ca-47f5-a53f-1e03f4db5110",
   "metadata": {},
   "source": [
    "After inference, we need to post process the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9781d77d-7d19-461f-8b6a-d95825c4d8c2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Convert the tensor to a PIL image\n",
    "pil_image = transforms.ToPILImage()(x[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed63933e-3fa0-4623-856f-dc48bb2dfd7f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502ad87a-f8db-48e6-b658-393d8f0ee07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_conf_threshold = .5\n",
    "\n",
    "pred_dict = apply_conf_threshold_instances(pred_list[0], bbox_conf_threshold=bbox_conf_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0ba2f4-7e5a-4754-a939-9e2c2b51c2c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_class_arr = apply_conf_threshold_masks(pred_dict, mask_conf_threshold=.5, size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535221bc-3792-4738-8b2d-a88615e4f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_conf_threshold_masks??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9968945a-4a35-4030-b087-49e06c55211c",
   "metadata": {},
   "source": [
    "The output of the last thresholding step is a 2D array of classes. we use this for pixel-wise evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc8050c-9c9e-4c04-9cdb-10a5fc440261",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_class_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188c269f-6f0b-4302-a763-9f0396e3965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "skio.imshow(test_img[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a81462-e143-4fea-bdfd-30eb7dab7b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unique(merged_class_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb54fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as skio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371f1b9d-c6cf-4048-a236-ffd4784331bd",
   "metadata": {},
   "source": [
    "This array has two values, 2 for vessels and 0 for background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d1e365-102c-4082-ab33-ec99e85541fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "skio.imshow(merged_class_arr.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4b36ba-ecba-4a8f-8766-2132d5f67954",
   "metadata": {},
   "source": [
    "Next, we set up the data loader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a3723c-46e2-4c8f-9d09-dbec26cb5c32",
   "metadata": {},
   "source": [
    "## Confusion Matrix Comparison for Unet and MaskRCNN\n",
    "\n",
    "In this section we create and compare pixel-wise confusion matrices and instance-wise confusion matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26748d0-0420-46fc-b5b3-23f59582470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ceruleanml.evaluation import get_cm_for_torchscript_model_unet, get_cm_for_torchscript_model_mrcnn\n",
    "from ceruleanml.data import class_mapping_coco\n",
    "from icevision.metrics.confusion_matrix import SimpleConfusionMatrix\n",
    "from icevision.metrics.confusion_matrix.confusion_matrix import MatchingPolicy\n",
    "from icevision.models.checkpoint import model_from_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1db5773-f28b-44b9-9ce5-a23e880e457c",
   "metadata": {},
   "source": [
    "The pixel wise mrcnn cm is correct. TODO this doesn't work with negative samples, only the instance confusion matrix does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9051234f-c28c-43f0-a475-3cf7b5bb5831",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_cm_for_torchscript_model_mrcnn??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32642079-8e1a-4eb2-bcf2-160e785d26ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "cm_mrcnn, f1_mrcnn = get_cm_for_torchscript_model_mrcnn(\n",
    "    valid_ds, scripted_model, save_path=icevision_experiment_dir, mask_conf_threshold=.01, bbox_conf_threshold=.7, num_classes=3, normalize=None, class_names=[\"background\", \"infra_slick\", \"recent_vessel\"], title=\"Torchvision MaskR-CNN Confusion Matrix: 20_Jul_2022_00_14_15\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f2dbbc-f7d0-48c0-9965-5a415e8f2492",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_mrcnn, f1_mrcnn = get_cm_for_torchscript_model_mrcnn(\n",
    "    valid_ds, scripted_model, save_path=icevision_experiment_dir, mask_conf_threshold=.01, bbox_conf_threshold=.7, num_classes=3, normalize=\"true\", class_names=[\"background\", \"infra_slick\", \"recent_vessel\"], title=\"Torchvision MaskR-CNN Confusion Matrix: 20_Jul_2022_00_14_15\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4763feb-892b-4758-bce7-261ebf62919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "_ = cm.finalize()\n",
    "\n",
    "cm.plot(figsize=5, normalize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b62a01-6bbd-4a1a-a1c3-90b23427e8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1A_IW_GRDH_1SDV_20200724T020738_20200724T020804_033590_03E494_B457\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:slickformer]",
   "language": "python",
   "name": "conda-env-slickformer-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
