{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ee1fe2e-ec07-4576-9133-ca106bf70743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn  # PyTorch Lightning NN (neural network) module\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, default_collate\n",
    "from torchdata.dataloader2 import DataLoader2\n",
    "import torchdata\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import DeviceStatsMonitor\n",
    "from ceruleanml import plot\n",
    "from ceruleanml import evaluation\n",
    "from ceruleanml.data_pipeline import put_image_in_dict, get_src_pths_annotations, channel_first_norm_to_tensor, stack_tensors\n",
    "from transformers import AutoModelForUniversalSegmentation\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "# Set the random seed\n",
    "seed=0 # we need to set this for torch datapipe separately\n",
    "random.seed(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb4221d9",
   "metadata": {},
   "source": [
    "Loading the train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d195c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"../data/partitions/train_tiles_context_0/\"\n",
    "train_imgs, train_annotations = get_src_pths_annotations(train_dir)\n",
    "val_dir = \"../data/partitions/val_tiles_context_0/\"\n",
    "val_imgs, val_annotations = get_src_pths_annotations(val_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ee0fa38",
   "metadata": {},
   "source": [
    "Setting up the datapipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc5e331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_i_coco_pipe = torchdata.datapipes.iter.IterableWrapper(iterable=[train_annotations])\n",
    "train_l_coco_pipe = torchdata.datapipes.iter.IterableWrapper(iterable=[train_annotations])\n",
    "train_source_pipe_processed = (\n",
    "    train_i_coco_pipe.get_scene_paths(train_dir)  # get source items from the collection\n",
    "    .read_tiff()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df307af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_pipe_processed = (\n",
    "    train_l_coco_pipe.decode_masks()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af92fd92",
   "metadata": {},
   "source": [
    "We'll train on random crops of masks to focus on the most informative parts of scene for more efficient training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f26f697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dp = (\n",
    "    train_source_pipe_processed.zip(train_labels_pipe_processed)\n",
    "    .random_crop_mask_if_exists(2000,2000)\n",
    "    .map(channel_first_norm_to_tensor)\n",
    "    .map(stack_tensors)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cd39903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.1.0 (20230122.1345)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"234pt\" height=\"357pt\"\n",
       " viewBox=\"0.00 0.00 234.00 357.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 353)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-353 230,-353 230,4 -4,4\"/>\n",
       "<!-- DecodeMasks&#45;8753591031232 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>DecodeMasks&#45;8753591031232</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"207,-239 124,-239 124,-220 207,-220 207,-239\"/>\n",
       "<text text-anchor=\"middle\" x=\"165.5\" y=\"-227\" font-family=\"monospace\" font-size=\"10.00\">DecodeMasks</text>\n",
       "</g>\n",
       "<!-- Zipper&#45;8753591031349 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Zipper&#45;8753591031349</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"139.5,-184 85.5,-184 85.5,-165 139.5,-165 139.5,-184\"/>\n",
       "<text text-anchor=\"middle\" x=\"112.5\" y=\"-172\" font-family=\"monospace\" font-size=\"10.00\">Zipper</text>\n",
       "</g>\n",
       "<!-- DecodeMasks&#45;8753591031232&#45;&gt;Zipper&#45;8753591031349 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>DecodeMasks&#45;8753591031232&#45;&gt;Zipper&#45;8753591031349</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M156.75,-219.75C149.35,-212.35 138.54,-201.54 129.45,-192.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"132.06,-190.11 122.51,-185.51 127.11,-195.06 132.06,-190.11\"/>\n",
       "</g>\n",
       "<!-- RandomCropByMasks&#45;8753591030803 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>RandomCropByMasks&#45;8753591030803</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"172,-129 53,-129 53,-110 172,-110 172,-129\"/>\n",
       "<text text-anchor=\"middle\" x=\"112.5\" y=\"-117\" font-family=\"monospace\" font-size=\"10.00\">RandomCropByMasks</text>\n",
       "</g>\n",
       "<!-- Zipper&#45;8753591031349&#45;&gt;RandomCropByMasks&#45;8753591030803 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>Zipper&#45;8753591031349&#45;&gt;RandomCropByMasks&#45;8753591030803</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M112.5,-164.75C112.5,-158.27 112.5,-149.16 112.5,-140.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"116,-140.96 112.5,-130.96 109,-140.96 116,-140.96\"/>\n",
       "</g>\n",
       "<!-- Mapper&#45;8753380335490 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Mapper&#45;8753380335490</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"139.5,-19 85.5,-19 85.5,0 139.5,0 139.5,-19\"/>\n",
       "<text text-anchor=\"middle\" x=\"112.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\">Mapper</text>\n",
       "</g>\n",
       "<!-- GetScenePaths&#45;8753588349925 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>GetScenePaths&#45;8753588349925</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-294 6,-294 6,-275 101,-275 101,-294\"/>\n",
       "<text text-anchor=\"middle\" x=\"53.5\" y=\"-282\" font-family=\"monospace\" font-size=\"10.00\">GetScenePaths</text>\n",
       "</g>\n",
       "<!-- ReadTiff&#45;8753380315773 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>ReadTiff&#45;8753380315773</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"93,-239 28,-239 28,-220 93,-220 93,-239\"/>\n",
       "<text text-anchor=\"middle\" x=\"60.5\" y=\"-227\" font-family=\"monospace\" font-size=\"10.00\">ReadTiff</text>\n",
       "</g>\n",
       "<!-- GetScenePaths&#45;8753588349925&#45;&gt;ReadTiff&#45;8753380315773 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>GetScenePaths&#45;8753588349925&#45;&gt;ReadTiff&#45;8753380315773</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.66,-274.75C55.52,-268.19 56.74,-258.95 57.84,-250.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"61.28,-251.31 59.12,-240.94 54.34,-250.4 61.28,-251.31\"/>\n",
       "</g>\n",
       "<!-- ReadTiff&#45;8753380315773&#45;&gt;Zipper&#45;8753591031349 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>ReadTiff&#45;8753380315773&#45;&gt;Zipper&#45;8753591031349</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M69.09,-219.75C76.34,-212.35 86.95,-201.54 95.87,-192.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"98.16,-195.11 102.67,-185.52 93.16,-190.21 98.16,-195.11\"/>\n",
       "</g>\n",
       "<!-- Mapper&#45;8753591031079 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>Mapper&#45;8753591031079</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"139.5,-74 85.5,-74 85.5,-55 139.5,-55 139.5,-74\"/>\n",
       "<text text-anchor=\"middle\" x=\"112.5\" y=\"-62\" font-family=\"monospace\" font-size=\"10.00\">Mapper</text>\n",
       "</g>\n",
       "<!-- Mapper&#45;8753591031079&#45;&gt;Mapper&#45;8753380335490 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Mapper&#45;8753591031079&#45;&gt;Mapper&#45;8753380335490</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M112.5,-54.75C112.5,-48.27 112.5,-39.16 112.5,-30.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"116,-30.96 112.5,-20.96 109,-30.96 116,-30.96\"/>\n",
       "</g>\n",
       "<!-- IterableWrapper&#45;8753380335499 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>IterableWrapper&#45;8753380335499</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"107,-349 0,-349 0,-330 107,-330 107,-349\"/>\n",
       "<text text-anchor=\"middle\" x=\"53.5\" y=\"-337\" font-family=\"monospace\" font-size=\"10.00\">IterableWrapper</text>\n",
       "</g>\n",
       "<!-- IterableWrapper&#45;8753380335499&#45;&gt;GetScenePaths&#45;8753588349925 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>IterableWrapper&#45;8753380335499&#45;&gt;GetScenePaths&#45;8753588349925</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M53.5,-329.75C53.5,-323.27 53.5,-314.16 53.5,-305.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"57,-305.96 53.5,-295.96 50,-305.96 57,-305.96\"/>\n",
       "</g>\n",
       "<!-- RandomCropByMasks&#45;8753591030803&#45;&gt;Mapper&#45;8753591031079 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>RandomCropByMasks&#45;8753591030803&#45;&gt;Mapper&#45;8753591031079</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M112.5,-109.75C112.5,-103.27 112.5,-94.16 112.5,-85.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"116,-85.96 112.5,-75.96 109,-85.96 116,-85.96\"/>\n",
       "</g>\n",
       "<!-- IterableWrapper&#45;8753588349814 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>IterableWrapper&#45;8753588349814</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"226,-294 119,-294 119,-275 226,-275 226,-294\"/>\n",
       "<text text-anchor=\"middle\" x=\"172.5\" y=\"-282\" font-family=\"monospace\" font-size=\"10.00\">IterableWrapper</text>\n",
       "</g>\n",
       "<!-- IterableWrapper&#45;8753588349814&#45;&gt;DecodeMasks&#45;8753591031232 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>IterableWrapper&#45;8753588349814&#45;&gt;DecodeMasks&#45;8753591031232</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M171.34,-274.75C170.48,-268.19 169.26,-258.95 168.16,-250.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"171.66,-250.4 166.88,-240.94 164.72,-251.31 171.66,-250.4\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f61aaf151b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchdata.datapipes.utils.to_graph(dp=train_dp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "294b9be4",
   "metadata": {},
   "source": [
    "Putting datapipes in a pytorch-lightning DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5a120b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class OneFormerDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_dir, val_dir, test_dir, batch_size, num_workers, crop_size=2000):\n",
    "        super().__init__()\n",
    "        self.train_dir, self.val_dir, self.test_dir = train_dir, val_dir, test_dir\n",
    "        self.bs = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.crop_size = crop_size\n",
    "\n",
    "    def setup(self, stage):\n",
    "        if stage is not None:  # train/val/test/predict\n",
    "            train_imgs, train_annotations = get_src_pths_annotations(self.train_dir)\n",
    "            train_i_coco_pipe = torchdata.datapipes.iter.IterableWrapper(iterable=[train_annotations])\n",
    "            train_l_coco_pipe = torchdata.datapipes.iter.IterableWrapper(iterable=[train_annotations])\n",
    "            train_source_pipe_processed = (\n",
    "                train_i_coco_pipe.get_scene_paths(self.train_dir)  # get source items from the collection\n",
    "                .read_tiff()\n",
    "            )\n",
    "            train_labels_pipe_processed = (\n",
    "                train_l_coco_pipe.decode_masks()\n",
    "            )\n",
    "            self.train_dp = (\n",
    "                train_source_pipe_processed.zip(train_labels_pipe_processed)\n",
    "                .random_crop_mask_if_exists(self.crop_size, self.crop_size)\n",
    "                .map(channel_first_norm_to_tensor)\n",
    "                .map(stack_tensors)\n",
    "            )\n",
    "            # TODO if val processing mirrors train processing, this could be factored out to a func\n",
    "            val_imgs, val_annotations = get_src_pths_annotations(self.val_dir)\n",
    "            val_i_coco_pipe = torchdata.datapipes.iter.IterableWrapper(iterable=[val_annotations])\n",
    "            val_l_coco_pipe = torchdata.datapipes.iter.IterableWrapper(iterable=[val_annotations])\n",
    "            val_source_pipe_processed = (\n",
    "                val_i_coco_pipe.get_scene_paths(self.val_dir) # get source items from the collection\n",
    "                .  read_tiff()\n",
    "            )\n",
    "            val_labels_pipe_processed = (\n",
    "                val_l_coco_pipe.decode_masks()\n",
    "            )\n",
    "            self.val_dp = (\n",
    "                val_source_pipe_processed.zip(val_labels_pipe_processed)\n",
    "                .random_crop_mask_if_exists(self.crop_size,self.crop_size)\n",
    "                .map(channel_first_norm_to_tensor)\n",
    "                .map(stack_tensors)\n",
    "            )\n",
    "\n",
    "            test_imgs, test_annotations = get_src_pths_annotations(self.test_dir)\n",
    "            test_i_coco_pipe = torchdata.datapipes.iter.IterableWrapper(iterable=[test_annotations])\n",
    "            test_l_coco_pipe = torchdata.datapipes.iter.IterableWrapper(iterable=[test_annotations])\n",
    "            test_source_pipe_processed = (\n",
    "            test_i_coco_pipe.get_scene_paths(self.test_dir) # get source items from the collection\n",
    "                .read_tiff()\n",
    "                .map(put_image_in_dict)\n",
    "                .map(channel_first_norm_to_tensor)\n",
    "            )\n",
    "            test_labels_pipe_processed = (\n",
    "                test_l_coco_pipe.decode_masks()\n",
    "            )\n",
    "            self.test_dp = (\n",
    "            test_source_pipe_processed.zip(test_labels_pipe_processed)\n",
    "            .combine_src_label_dicts() # we don't crop for the test set TODO, do we also not crop for validation?\n",
    "            .map(channel_first_norm_to_tensor)\n",
    "            .map(stack_tensors)\n",
    "            )\n",
    "\n",
    "    def graph_dp(self):\n",
    "        return torchdata.datapipes.utils.to_graph(dp=self.train_dp)\n",
    "\n",
    "    def show_batch(self):\n",
    "        fig, axes = plt.subplots(nrows=4, ncols=int(self.bs / 4))\n",
    "        for item, ax in zip(self.train_dp, axes.flatten()):\n",
    "            vv_db_units = np.log10(item[\"image\"][:,:,0]) * 10\n",
    "            tgt = item[\"label\"]\n",
    "            ax.imshow(vv_db_units, cmap=\"bwr\")\n",
    "            ax.set_title(tgt)\n",
    "        plt.tight_layout()\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(dataset=self.train_dp, batch_size=self.bs)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(dataset=self.val_dp, batch_size=self.bs)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(dataset=self.test_dp, batch_size=self.bs)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(dataset=self.test_dp, batch_size=self.bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cffb63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334df29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backbone(nn.Module):\n",
    "    def __init__(\n",
    "        self, model_name, in_chans, num_classes, pretrained, global_pool, drop_rate\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # loads from huggingface if not downloaded\n",
    "        self.backbone = AutoModelForUniversalSegmentation.from_pretrained(\"shi-labs/oneformer_coco_swin_large\").model\n",
    "        #by default the above method sets eval mode, set to training\n",
    "        self.backbone.train()\n",
    "        timm.create_model(\n",
    "            model_name=model_name,\n",
    "            in_chans=in_chans,\n",
    "            num_classes=num_classes,\n",
    "            pretrained=pretrained,\n",
    "            global_pool=global_pool,\n",
    "            drop_rate=drop_rate,\n",
    "        )\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.backbone(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6f6422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = AutoModelForUniversalSegmentation.from_pretrained(\"shi-labs/oneformer_coco_swin_large\").model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1d4bb82",
   "metadata": {},
   "source": [
    "TODO what are the model args??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f48d9266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mAutoModelForUniversalSegmentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Instantiate one of the model classes of the library (with a universal image segmentation head) from a pretrained model.\n",
      "\n",
      "The model class to instantiate is selected based on the `model_type` property of the config object (either\n",
      "passed as an argument or loaded from `pretrained_model_name_or_path` if possible), or when it's missing, by\n",
      "falling back to using pattern matching on `pretrained_model_name_or_path`:\n",
      "\n",
      "    - **detr** -- [`DetrForSegmentation`] (DETR model)\n",
      "    - **mask2former** -- [`Mask2FormerForUniversalSegmentation`] (Mask2Former model)\n",
      "    - **maskformer** -- [`MaskFormerForInstanceSegmentation`] (MaskFormer model)\n",
      "    - **oneformer** -- [`OneFormerForUniversalSegmentation`] (OneFormer model)\n",
      "\n",
      "The model is set in evaluation mode by default using `model.eval()` (so for instance, dropout modules are\n",
      "deactivated). To train the model, you should first set it back in training mode with `model.train()`\n",
      "\n",
      "Args:\n",
      "    pretrained_model_name_or_path (`str` or `os.PathLike`):\n",
      "        Can be either:\n",
      "\n",
      "            - A string, the *model id* of a pretrained model hosted inside a model repo on huggingface.co.\n",
      "              Valid model ids can be located at the root-level, like `bert-base-uncased`, or namespaced under a\n",
      "              user or organization name, like `dbmdz/bert-base-german-cased`.\n",
      "            - A path to a *directory* containing model weights saved using\n",
      "              [`~PreTrainedModel.save_pretrained`], e.g., `./my_model_directory/`.\n",
      "            - A path or url to a *tensorflow index checkpoint file* (e.g, `./tf_model/model.ckpt.index`). In\n",
      "              this case, `from_tf` should be set to `True` and a configuration object should be provided as\n",
      "              `config` argument. This loading path is slower than converting the TensorFlow checkpoint in a\n",
      "              PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.\n",
      "    model_args (additional positional arguments, *optional*):\n",
      "        Will be passed along to the underlying model `__init__()` method.\n",
      "    config ([`PretrainedConfig`], *optional*):\n",
      "        Configuration for the model to use instead of an automatically loaded configuration. Configuration can\n",
      "        be automatically loaded when:\n",
      "\n",
      "            - The model is a model provided by the library (loaded with the *model id* string of a pretrained\n",
      "              model).\n",
      "            - The model was saved using [`~PreTrainedModel.save_pretrained`] and is reloaded by supplying the\n",
      "              save directory.\n",
      "            - The model is loaded by supplying a local directory as `pretrained_model_name_or_path` and a\n",
      "              configuration JSON file named *config.json* is found in the directory.\n",
      "    state_dict (*Dict[str, torch.Tensor]*, *optional*):\n",
      "        A state dictionary to use instead of a state dictionary loaded from saved weights file.\n",
      "\n",
      "        This option can be used if you want to create a model from a pretrained configuration but load your own\n",
      "        weights. In this case though, you should check if using [`~PreTrainedModel.save_pretrained`] and\n",
      "        [`~PreTrainedModel.from_pretrained`] is not a simpler option.\n",
      "    cache_dir (`str` or `os.PathLike`, *optional*):\n",
      "        Path to a directory in which a downloaded pretrained model configuration should be cached if the\n",
      "        standard cache should not be used.\n",
      "    from_tf (`bool`, *optional*, defaults to `False`):\n",
      "        Load the model weights from a TensorFlow checkpoint save file (see docstring of\n",
      "        `pretrained_model_name_or_path` argument).\n",
      "    force_download (`bool`, *optional*, defaults to `False`):\n",
      "        Whether or not to force the (re-)download of the model weights and configuration files, overriding the\n",
      "        cached versions if they exist.\n",
      "    resume_download (`bool`, *optional*, defaults to `False`):\n",
      "        Whether or not to delete incompletely received files. Will attempt to resume the download if such a\n",
      "        file exists.\n",
      "    proxies (`Dict[str, str]`, *optional*):\n",
      "        A dictionary of proxy servers to use by protocol or endpoint, e.g., `{'http': 'foo.bar:3128',\n",
      "        'http://hostname': 'foo.bar:4012'}`. The proxies are used on each request.\n",
      "    output_loading_info(`bool`, *optional*, defaults to `False`):\n",
      "        Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.\n",
      "    local_files_only(`bool`, *optional*, defaults to `False`):\n",
      "        Whether or not to only look at local files (e.g., not try downloading the model).\n",
      "    revision (`str`, *optional*, defaults to `\"main\"`):\n",
      "        The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n",
      "        git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any\n",
      "        identifier allowed by git.\n",
      "    trust_remote_code (`bool`, *optional*, defaults to `False`):\n",
      "        Whether or not to allow for custom models defined on the Hub in their own modeling files. This option\n",
      "        should only be set to `True` for repositories you trust and in which you have read the code, as it will\n",
      "        execute code present on the Hub on your local machine.\n",
      "    kwargs (additional keyword arguments, *optional*):\n",
      "        Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,\n",
      "        `output_attentions=True`). Behaves differently depending on whether a `config` is provided or\n",
      "        automatically loaded:\n",
      "\n",
      "            - If a configuration is provided with `config`, `**kwargs` will be directly passed to the\n",
      "              underlying model's `__init__` method (we assume all relevant updates to the configuration have\n",
      "              already been done)\n",
      "            - If a configuration is not provided, `kwargs` will be first passed to the configuration class\n",
      "              initialization function ([`~PretrainedConfig.from_pretrained`]). Each key of `kwargs` that\n",
      "              corresponds to a configuration attribute will be used to override said attribute with the\n",
      "              supplied `kwargs` value. Remaining keys that do not correspond to any configuration attribute\n",
      "              will be passed to the underlying model's `__init__` function.\n",
      "\n",
      "Examples:\n",
      "\n",
      "```python\n",
      ">>> from transformers import AutoConfig, AutoModelForUniversalSegmentation\n",
      "\n",
      ">>> # Download model and configuration from huggingface.co and cache.\n",
      ">>> model = AutoModelForUniversalSegmentation.from_pretrained(\"bert-base-cased\")\n",
      "\n",
      ">>> # Update configuration during loading\n",
      ">>> model = AutoModelForUniversalSegmentation.from_pretrained(\"bert-base-cased\", output_attentions=True)\n",
      ">>> model.config.output_attentions\n",
      "True\n",
      "\n",
      ">>> # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n",
      ">>> config = AutoConfig.from_pretrained(\"./tf_model/bert_tf_model_config.json\")\n",
      ">>> model = AutoModelForUniversalSegmentation.from_pretrained(\n",
      "...     \"./tf_model/bert_tf_checkpoint.ckpt.index\", from_tf=True, config=config\n",
      "... )\n",
      "```\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "    \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mtrust_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trust_remote_code\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_from_auto\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mhub_kwargs_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"cache_dir\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"force_download\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"local_files_only\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"proxies\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"resume_download\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"revision\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"subfolder\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"use_auth_token\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mhub_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhub_kwargs_names\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mkwargs_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# ensure not to pollute the config object with torch_dtype=\"auto\" - since it's\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# meaningless in the context of the config object - torch.dtype values are acceptable\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mkwargs_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torch_dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torch_dtype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mreturn_unused_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m**\u001b[0m\u001b[0mkwargs_copy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34mf\"Loading {pretrained_model_name_or_path} requires you to execute the modeling file in that repo \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"on your local machine. Make sure you have read the code there to avoid malicious use, then set \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"the option `trust_remote_code=True` to remove this error.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mhub_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"revision\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"no malicious code has been contributed in a newer revision.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mclass_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmodule_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_class_from_dynamic_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_file\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".py\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_for_auto_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34mf\"Unrecognized configuration class {config.__class__} for this kind of AutoModel: {cls.__name__}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34mf\"Model type should be one of {', '.join(c.__name__ for c in cls._model_mapping.keys())}.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/mambaforge/envs/slickformer/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "AutoModelForUniversalSegmentation.from_pretrained??"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83dafc5d",
   "metadata": {},
   "source": [
    "transformers demo and model weight download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bab59ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoProcessor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# the Auto API loads a OneFormerProcessor for us, based on the checkpoint\n",
    "processor = AutoProcessor.from_pretrained(\"shi-labs/oneformer_coco_swin_large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a1a321a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mAutoProcessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Instantiate one of the processor classes of the library from a pretrained model vocabulary.\n",
      "\n",
      "The processor class to instantiate is selected based on the `model_type` property of the config object (either\n",
      "passed as an argument or loaded from `pretrained_model_name_or_path` if possible):\n",
      "\n",
      "    - **align** -- [`AlignProcessor`] (ALIGN model)\n",
      "    - **altclip** -- [`AltCLIPProcessor`] (AltCLIP model)\n",
      "    - **blip** -- [`BlipProcessor`] (BLIP model)\n",
      "    - **blip-2** -- [`Blip2Processor`] (BLIP-2 model)\n",
      "    - **bridgetower** -- [`BridgeTowerProcessor`] (BridgeTower model)\n",
      "    - **chinese_clip** -- [`ChineseCLIPProcessor`] (Chinese-CLIP model)\n",
      "    - **clap** -- [`ClapProcessor`] (CLAP model)\n",
      "    - **clip** -- [`CLIPProcessor`] (CLIP model)\n",
      "    - **clipseg** -- [`CLIPSegProcessor`] (CLIPSeg model)\n",
      "    - **flava** -- [`FlavaProcessor`] (FLAVA model)\n",
      "    - **git** -- [`GitProcessor`] (GIT model)\n",
      "    - **groupvit** -- [`CLIPProcessor`] (GroupViT model)\n",
      "    - **hubert** -- [`Wav2Vec2Processor`] (Hubert model)\n",
      "    - **layoutlmv2** -- [`LayoutLMv2Processor`] (LayoutLMv2 model)\n",
      "    - **layoutlmv3** -- [`LayoutLMv3Processor`] (LayoutLMv3 model)\n",
      "    - **markuplm** -- [`MarkupLMProcessor`] (MarkupLM model)\n",
      "    - **mgp-str** -- [`MgpstrProcessor`] (MGP-STR model)\n",
      "    - **oneformer** -- [`OneFormerProcessor`] (OneFormer model)\n",
      "    - **owlvit** -- [`OwlViTProcessor`] (OWL-ViT model)\n",
      "    - **sew** -- [`Wav2Vec2Processor`] (SEW model)\n",
      "    - **sew-d** -- [`Wav2Vec2Processor`] (SEW-D model)\n",
      "    - **speech_to_text** -- [`Speech2TextProcessor`] (Speech2Text model)\n",
      "    - **speech_to_text_2** -- [`Speech2Text2Processor`] (Speech2Text2 model)\n",
      "    - **speecht5** -- [`SpeechT5Processor`] (SpeechT5 model)\n",
      "    - **trocr** -- [`TrOCRProcessor`] (TrOCR model)\n",
      "    - **tvlt** -- [`TvltProcessor`] (TVLT model)\n",
      "    - **unispeech** -- [`Wav2Vec2Processor`] (UniSpeech model)\n",
      "    - **unispeech-sat** -- [`Wav2Vec2Processor`] (UniSpeechSat model)\n",
      "    - **vilt** -- [`ViltProcessor`] (ViLT model)\n",
      "    - **vision-text-dual-encoder** -- [`VisionTextDualEncoderProcessor`] (VisionTextDualEncoder model)\n",
      "    - **wav2vec2** -- [`Wav2Vec2Processor`] (Wav2Vec2 model)\n",
      "    - **wav2vec2-conformer** -- [`Wav2Vec2Processor`] (Wav2Vec2-Conformer model)\n",
      "    - **wavlm** -- [`Wav2Vec2Processor`] (WavLM model)\n",
      "    - **whisper** -- [`WhisperProcessor`] (Whisper model)\n",
      "    - **xclip** -- [`XCLIPProcessor`] (X-CLIP model)\n",
      "\n",
      "Params:\n",
      "    pretrained_model_name_or_path (`str` or `os.PathLike`):\n",
      "        This can be either:\n",
      "\n",
      "        - a string, the *model id* of a pretrained feature_extractor hosted inside a model repo on\n",
      "          huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`, or\n",
      "          namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.\n",
      "        - a path to a *directory* containing a processor files saved using the `save_pretrained()` method,\n",
      "          e.g., `./my_model_directory/`.\n",
      "    cache_dir (`str` or `os.PathLike`, *optional*):\n",
      "        Path to a directory in which a downloaded pretrained model feature extractor should be cached if the\n",
      "        standard cache should not be used.\n",
      "    force_download (`bool`, *optional*, defaults to `False`):\n",
      "        Whether or not to force to (re-)download the feature extractor files and override the cached versions\n",
      "        if they exist.\n",
      "    resume_download (`bool`, *optional*, defaults to `False`):\n",
      "        Whether or not to delete incompletely received file. Attempts to resume the download if such a file\n",
      "        exists.\n",
      "    proxies (`Dict[str, str]`, *optional*):\n",
      "        A dictionary of proxy servers to use by protocol or endpoint, e.g., `{'http': 'foo.bar:3128',\n",
      "        'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.\n",
      "    use_auth_token (`str` or *bool*, *optional*):\n",
      "        The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n",
      "        when running `huggingface-cli login` (stored in `~/.huggingface`).\n",
      "    revision (`str`, *optional*, defaults to `\"main\"`):\n",
      "        The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n",
      "        git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any\n",
      "        identifier allowed by git.\n",
      "    return_unused_kwargs (`bool`, *optional*, defaults to `False`):\n",
      "        If `False`, then this function returns just the final feature extractor object. If `True`, then this\n",
      "        functions returns a `Tuple(feature_extractor, unused_kwargs)` where *unused_kwargs* is a dictionary\n",
      "        consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of\n",
      "        `kwargs` which has not been used to update `feature_extractor` and is otherwise ignored.\n",
      "    trust_remote_code (`bool`, *optional*, defaults to `False`):\n",
      "        Whether or not to allow for custom models defined on the Hub in their own modeling files. This option\n",
      "        should only be set to `True` for repositories you trust and in which you have read the code, as it will\n",
      "        execute code present on the Hub on your local machine.\n",
      "    kwargs (`Dict[str, Any]`, *optional*):\n",
      "        The values in kwargs of any keys which are feature extractor attributes will be used to override the\n",
      "        loaded values. Behavior concerning key/value pairs whose keys are *not* feature extractor attributes is\n",
      "        controlled by the `return_unused_kwargs` keyword parameter.\n",
      "\n",
      "<Tip>\n",
      "\n",
      "Passing `use_auth_token=True` is required when you want to use a private model.\n",
      "\n",
      "</Tip>\n",
      "\n",
      "Examples:\n",
      "\n",
      "```python\n",
      ">>> from transformers import AutoProcessor\n",
      "\n",
      ">>> # Download processor from huggingface.co and cache.\n",
      ">>> processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
      "\n",
      ">>> # If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)\n",
      ">>> processor = AutoProcessor.from_pretrained(\"./test/saved_model/\")\n",
      "```\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "    \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mreplace_list_option_in_docstrings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPROCESSOR_MAPPING_NAMES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"\u001b[0m\n",
      "\u001b[0;34m        Instantiate one of the processor classes of the library from a pretrained model vocabulary.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        The processor class to instantiate is selected based on the `model_type` property of the config object (either\u001b[0m\n",
      "\u001b[0;34m        passed as an argument or loaded from `pretrained_model_name_or_path` if possible):\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        List options\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Params:\u001b[0m\n",
      "\u001b[0;34m            pretrained_model_name_or_path (`str` or `os.PathLike`):\u001b[0m\n",
      "\u001b[0;34m                This can be either:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m                - a string, the *model id* of a pretrained feature_extractor hosted inside a model repo on\u001b[0m\n",
      "\u001b[0;34m                  huggingface.co. Valid model ids can be located at the root-level, like `bert-base-uncased`, or\u001b[0m\n",
      "\u001b[0;34m                  namespaced under a user or organization name, like `dbmdz/bert-base-german-cased`.\u001b[0m\n",
      "\u001b[0;34m                - a path to a *directory* containing a processor files saved using the `save_pretrained()` method,\u001b[0m\n",
      "\u001b[0;34m                  e.g., `./my_model_directory/`.\u001b[0m\n",
      "\u001b[0;34m            cache_dir (`str` or `os.PathLike`, *optional*):\u001b[0m\n",
      "\u001b[0;34m                Path to a directory in which a downloaded pretrained model feature extractor should be cached if the\u001b[0m\n",
      "\u001b[0;34m                standard cache should not be used.\u001b[0m\n",
      "\u001b[0;34m            force_download (`bool`, *optional*, defaults to `False`):\u001b[0m\n",
      "\u001b[0;34m                Whether or not to force to (re-)download the feature extractor files and override the cached versions\u001b[0m\n",
      "\u001b[0;34m                if they exist.\u001b[0m\n",
      "\u001b[0;34m            resume_download (`bool`, *optional*, defaults to `False`):\u001b[0m\n",
      "\u001b[0;34m                Whether or not to delete incompletely received file. Attempts to resume the download if such a file\u001b[0m\n",
      "\u001b[0;34m                exists.\u001b[0m\n",
      "\u001b[0;34m            proxies (`Dict[str, str]`, *optional*):\u001b[0m\n",
      "\u001b[0;34m                A dictionary of proxy servers to use by protocol or endpoint, e.g., `{'http': 'foo.bar:3128',\u001b[0m\n",
      "\u001b[0;34m                'http://hostname': 'foo.bar:4012'}.` The proxies are used on each request.\u001b[0m\n",
      "\u001b[0;34m            use_auth_token (`str` or *bool*, *optional*):\u001b[0m\n",
      "\u001b[0;34m                The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\u001b[0m\n",
      "\u001b[0;34m                when running `huggingface-cli login` (stored in `~/.huggingface`).\u001b[0m\n",
      "\u001b[0;34m            revision (`str`, *optional*, defaults to `\"main\"`):\u001b[0m\n",
      "\u001b[0;34m                The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\u001b[0m\n",
      "\u001b[0;34m                git-based system for storing models and other artifacts on huggingface.co, so `revision` can be any\u001b[0m\n",
      "\u001b[0;34m                identifier allowed by git.\u001b[0m\n",
      "\u001b[0;34m            return_unused_kwargs (`bool`, *optional*, defaults to `False`):\u001b[0m\n",
      "\u001b[0;34m                If `False`, then this function returns just the final feature extractor object. If `True`, then this\u001b[0m\n",
      "\u001b[0;34m                functions returns a `Tuple(feature_extractor, unused_kwargs)` where *unused_kwargs* is a dictionary\u001b[0m\n",
      "\u001b[0;34m                consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of\u001b[0m\n",
      "\u001b[0;34m                `kwargs` which has not been used to update `feature_extractor` and is otherwise ignored.\u001b[0m\n",
      "\u001b[0;34m            trust_remote_code (`bool`, *optional*, defaults to `False`):\u001b[0m\n",
      "\u001b[0;34m                Whether or not to allow for custom models defined on the Hub in their own modeling files. This option\u001b[0m\n",
      "\u001b[0;34m                should only be set to `True` for repositories you trust and in which you have read the code, as it will\u001b[0m\n",
      "\u001b[0;34m                execute code present on the Hub on your local machine.\u001b[0m\n",
      "\u001b[0;34m            kwargs (`Dict[str, Any]`, *optional*):\u001b[0m\n",
      "\u001b[0;34m                The values in kwargs of any keys which are feature extractor attributes will be used to override the\u001b[0m\n",
      "\u001b[0;34m                loaded values. Behavior concerning key/value pairs whose keys are *not* feature extractor attributes is\u001b[0m\n",
      "\u001b[0;34m                controlled by the `return_unused_kwargs` keyword parameter.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        <Tip>\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Passing `use_auth_token=True` is required when you want to use a private model.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        </Tip>\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Examples:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        ```python\u001b[0m\n",
      "\u001b[0;34m        >>> from transformers import AutoProcessor\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        >>> # Download processor from huggingface.co and cache.\u001b[0m\n",
      "\u001b[0;34m        >>> processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-base-960h\")\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        >>> # If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)\u001b[0m\n",
      "\u001b[0;34m        >>> processor = AutoProcessor.from_pretrained(\"./test/saved_model/\")\u001b[0m\n",
      "\u001b[0;34m        ```\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mtrust_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trust_remote_code\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_from_auto\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mprocessor_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mprocessor_auto_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# First, let's see if we have a preprocessor config.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Filter the kwargs for `get_file_from_repo`.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mget_file_from_repo_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_file_from_repo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Let's start by checking whether the processor class is saved in an image processor\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mpreprocessor_config_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_file_from_repo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFEATURE_EXTRACTOR_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mget_file_from_repo_kwargs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor_config_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageProcessingMixin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image_processor_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mprocessor_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"processor_class\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;34m\"AutoProcessor\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mprocessor_auto_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"AutoProcessor\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# If not found, let's check whether the processor class is saved in a feature extractor config\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor_config_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mprocessor_class\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatureExtractionMixin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_extractor_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mprocessor_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"processor_class\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;34m\"AutoProcessor\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mprocessor_auto_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"AutoProcessor\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mprocessor_class\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Next, let's check whether the processor class is saved in a tokenizer\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtokenizer_config_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_file_from_repo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mget_file_from_repo_kwargs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mtokenizer_config_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer_config_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0mconfig_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mprocessor_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"processor_class\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0;34m\"AutoProcessor\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0mprocessor_auto_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"AutoProcessor\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mprocessor_class\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Otherwise, load config, if it can be loaded.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# And check if the config contains the processor class.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mprocessor_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"processor_class\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoProcessor\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mprocessor_auto_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"AutoProcessor\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mprocessor_class\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# If we have custom code for a feature extractor, we get the proper class.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mprocessor_auto_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0;34mf\"Loading {pretrained_model_name_or_path} requires you to execute the feature extractor file \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0;34m\"in that repo on your local machine. Make sure you have read the code there to avoid \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0;34m\"malicious use, then set the option `trust_remote_code=True` to remove this error.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"revision\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0;34m\"Explicitly passing a `revision` is encouraged when loading a feature extractor with custom \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0;34m\"code to ensure no malicious code has been contributed in a newer revision.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mmodule_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor_auto_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mprocessor_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_class_from_dynamic_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_file\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".py\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mprocessor_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_for_auto_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mprocessor_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor_class_from_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mprocessor_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Last try: we use the PROCESSOR_MAPPING.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPROCESSOR_MAPPING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mPROCESSOR_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# At this stage, there doesn't seem to be a `Processor` class available for this model, so let's try a\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# tokenizer.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mreturn\u001b[0m \u001b[0mAutoImageProcessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mreturn\u001b[0m \u001b[0mAutoFeatureExtractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34mf\"Unrecognized processing class in {pretrained_model_name_or_path}. Can't instantiate a processor, a \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"tokenizer, an image processor or a feature extractor for this model. Make sure the repository contains\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"the files of at least one of those processing classes.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/mambaforge/envs/slickformer/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "AutoProcessor.from_pretrained??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "316ccedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# panoptic_inputs = processor(images=image, task_inputs=[\"panoptic\"], return_tensors=\"pt\")\n",
    "# for k,v in panoptic_inputs.items():\n",
    "#   print(k,v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d094538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForUniversalSegmentation.from_pretrained(\"shi-labs/oneformer_coco_swin_large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "607ca343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.oneformer.modeling_oneformer.OneFormerForUniversalSegmentation"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1f9756d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_auto_class',\n",
       " '_backward_compatibility_gradient_checkpointing',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_convert_head_mask_to_5d',\n",
       " '_create_repo',\n",
       " '_expand_inputs_for_generation',\n",
       " '_extract_past_from_model_output',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_from_config',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_decoder_start_token_id',\n",
       " '_get_files_timestamps',\n",
       " '_get_logits_processor',\n",
       " '_get_logits_warper',\n",
       " '_get_name',\n",
       " '_get_resized_embeddings',\n",
       " '_get_resized_lm_head',\n",
       " '_get_stopping_criteria',\n",
       " '_hook_rss_memory_post_forward',\n",
       " '_hook_rss_memory_pre_forward',\n",
       " '_init_weights',\n",
       " '_initialize_weights',\n",
       " '_is_full_backward_hook',\n",
       " '_is_hf_initialized',\n",
       " '_keep_in_fp32_modules',\n",
       " '_keys_to_ignore_on_load_missing',\n",
       " '_keys_to_ignore_on_load_unexpected',\n",
       " '_keys_to_ignore_on_save',\n",
       " '_load_from_state_dict',\n",
       " '_load_pretrained_model',\n",
       " '_load_pretrained_model_low_mem',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_initialize_input_ids_for_generation',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_merge_criteria_processor_list',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_no_split_modules',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_prepare_attention_mask_for_generation',\n",
       " '_prepare_decoder_input_ids_for_generation',\n",
       " '_prepare_encoder_decoder_kwargs_for_generation',\n",
       " '_prepare_model_inputs',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_reorder_cache',\n",
       " '_replicate_for_data_parallel',\n",
       " '_resize_token_embeddings',\n",
       " '_save_to_state_dict',\n",
       " '_set_default_torch_dtype',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_tie_encoder_decoder_weights',\n",
       " '_tie_or_clone_weights',\n",
       " '_update_model_kwargs_for_generation',\n",
       " '_upload_modified_files',\n",
       " '_validate_model_class',\n",
       " '_validate_model_kwargs',\n",
       " '_version',\n",
       " 'add_memory_hooks',\n",
       " 'add_module',\n",
       " 'adjust_logits_during_generation',\n",
       " 'apply',\n",
       " 'base_model',\n",
       " 'base_model_prefix',\n",
       " 'beam_sample',\n",
       " 'beam_search',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'can_generate',\n",
       " 'children',\n",
       " 'compute_transition_scores',\n",
       " 'config',\n",
       " 'config_class',\n",
       " 'constrained_beam_search',\n",
       " 'contrastive_search',\n",
       " 'cpu',\n",
       " 'create_extended_attention_mask_for_decoder',\n",
       " 'cuda',\n",
       " 'device',\n",
       " 'disable_input_require_grads',\n",
       " 'double',\n",
       " 'dtype',\n",
       " 'dummy_inputs',\n",
       " 'dump_patches',\n",
       " 'enable_input_require_grads',\n",
       " 'estimate_tokens',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'floating_point_ops',\n",
       " 'forward',\n",
       " 'framework',\n",
       " 'from_pretrained',\n",
       " 'generate',\n",
       " 'generation_config',\n",
       " 'get_buffer',\n",
       " 'get_extended_attention_mask',\n",
       " 'get_extra_state',\n",
       " 'get_head_mask',\n",
       " 'get_input_embeddings',\n",
       " 'get_memory_footprint',\n",
       " 'get_output_embeddings',\n",
       " 'get_parameter',\n",
       " 'get_position_embeddings',\n",
       " 'get_submodule',\n",
       " 'gradient_checkpointing_disable',\n",
       " 'gradient_checkpointing_enable',\n",
       " 'greedy_search',\n",
       " 'group_beam_search',\n",
       " 'half',\n",
       " 'init_weights',\n",
       " 'invert_attention_mask',\n",
       " 'ipu',\n",
       " 'is_gradient_checkpointing',\n",
       " 'is_parallelizable',\n",
       " 'is_training',\n",
       " 'load_state_dict',\n",
       " 'main_input_name',\n",
       " 'modules',\n",
       " 'name_or_path',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'num_parameters',\n",
       " 'parameters',\n",
       " 'pixel_level_module',\n",
       " 'post_init',\n",
       " 'prepare_inputs_for_generation',\n",
       " 'prune_heads',\n",
       " 'push_to_hub',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_for_auto_class',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'reset_memory_hooks_state',\n",
       " 'resize_position_embeddings',\n",
       " 'resize_token_embeddings',\n",
       " 'retrieve_modules_from_names',\n",
       " 'sample',\n",
       " 'save_pretrained',\n",
       " 'set_extra_state',\n",
       " 'set_input_embeddings',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'supports_gradient_checkpointing',\n",
       " 'task_encoder',\n",
       " 'text_mapper',\n",
       " 'tie_weights',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'transformer_module',\n",
       " 'type',\n",
       " 'warnings_issued',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1461f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**panoptic_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ef8c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "panoptic_segmentation = processor.post_process_panoptic_segmentation(outputs, target_sizes=[image.size[::-1]])[0]\n",
    "print(panoptic_segmentation.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96a37dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def draw_panoptic_segmentation(segmentation, segments_info):\n",
    "    # get the used color map\n",
    "    viridis = cm.get_cmap('viridis', torch.max(segmentation))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(segmentation)\n",
    "    instances_counter = defaultdict(int)\n",
    "    handles = []\n",
    "    # for each segment, draw its legend\n",
    "    for segment in segments_info:\n",
    "        segment_id = segment['id']\n",
    "        segment_label_id = segment['label_id']\n",
    "        segment_label = model.config.id2label[segment_label_id]\n",
    "        label = f\"{segment_label}-{instances_counter[segment_label_id]}\"\n",
    "        instances_counter[segment_label_id] += 1\n",
    "        color = viridis(segment_id)\n",
    "        handles.append(mpatches.Patch(color=color, label=label))\n",
    "        \n",
    "    ax.legend(handles=handles)\n",
    "    plt.savefig('cats_panoptic.png')\n",
    "\n",
    "draw_panoptic_segmentation(**panoptic_segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c92905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57180d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a72b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee76a33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7531cf28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bec4a4b8",
   "metadata": {},
   "source": [
    "Groundtruth datapipe with non cropped images. We will use these for inference with the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6099f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_train_dp = (train_dp\n",
    "                    .map(evaluation.remap_gt_dict)\n",
    "                    .map(evaluation.stack_boxes)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70488c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import detection\n",
    "\n",
    "m = detection.mean_ap.MeanAveragePrecision(box_format='xyxy', iou_type='bbox', iou_thresholds=[.5], rec_thresholds=None, max_detection_thresholds=None, class_metrics=True)\n",
    "\n",
    "m.update(preds=[pred_dict_thresholded_nms], target=[test_sample])\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(m.compute())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slickformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
