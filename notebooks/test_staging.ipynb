{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchdata\n",
    "import random\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "# Set the random seed\n",
    "seed=0 # we need to set this for torch datapipe separately\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/slickformer/data/models/2023_02_18_00_38_07_4cls_rn152_pr512_px1024_1440min_maskrcnn_scripting_cpu_model.pt\"\n",
    "scripted_model = torch.jit.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scenes = [\"../data/tile_with_slick_512_512_3band.png\"] # from cerulean cloud test fixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ceruleanml.data_pipeline import put_image_in_dict, channel_first_norm_to_tensor\n",
    "source_pipe = torchdata.datapipes.iter.IterableWrapper(iterable=test_scenes)\n",
    "\n",
    "source = (source_pipe \n",
    "    .read_tiff()\n",
    "    .map(put_image_in_dict)\n",
    "    .map(channel_first_norm_to_tensor)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 512])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(source))['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time is an issue where there are lots of slicks\n",
    "from ceruleanml.inference import mrcnn_3_class_inference\n",
    "from ceruleanml.data_creation import class_dict\n",
    "\n",
    "bbox_conf_threshold = .2\n",
    "mask_conf_threshold=.2\n",
    "input_size=2000\n",
    "for idict in source:\n",
    "    pred_dict_thresholded, pred_dict = mrcnn_3_class_inference([idict['image']], scripted_model, bbox_conf_threshold, mask_conf_threshold, input_size=input_size)\n",
    "    pred_dict_thresholded_nms , pred_dict = mrcnn_3_class_inference([idict['image']], scripted_model, bbox_conf_threshold, mask_conf_threshold, input_size=input_size, interclass_nms_threshold=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'map': tensor(1.),\n",
      " 'map_50': tensor(1.),\n",
      " 'map_75': tensor(-1),\n",
      " 'map_large': tensor(1.),\n",
      " 'map_medium': tensor(-1.),\n",
      " 'map_per_class': tensor(1.),\n",
      " 'map_small': tensor(-1.),\n",
      " 'mar_1': tensor(1.),\n",
      " 'mar_10': tensor(1.),\n",
      " 'mar_100': tensor(1.),\n",
      " 'mar_100_per_class': tensor(1.),\n",
      " 'mar_large': tensor(1.),\n",
      " 'mar_medium': tensor(-1.),\n",
      " 'mar_small': tensor(-1.)}\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics import detection\n",
    "\n",
    "m = detection.mean_ap.MeanAveragePrecision(box_format='xyxy', iou_type='bbox', iou_thresholds=[.5], rec_thresholds=None, max_detection_thresholds=None, class_metrics=True)\n",
    "\n",
    "m.update(preds=[pred_dicts_thresholded_nms], target=[pred_dicts_thresholded_nms])\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(m.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import configparser\n",
    "import base64\n",
    "# parses secrets so we don't expose them in the notebook\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../.secrets')\n",
    "config = config['secrets']\n",
    "# reads image as bytes, converts bytes to string so it can be sent as a post request\n",
    "with open(test_scenes[0], 'rb') as f:\n",
    "    byte_string = f.read()\n",
    "    base64_string = base64.b64encode(byte_string).decode('utf-8')\n",
    "# we format the payload and headers according to what the docs expect\n",
    "# docs are at f\"{config['CERULEAN_STAGING_URL']}/docs\"\n",
    "predict_url = f\"{config['CERULEAN_STAGING_URL']}/predict\"\n",
    "payload = {\"stack\": [{\"image\": base64_string, \"bounds\":[ 0,0,0,0 ]}]}\n",
    "headers = {\"Authorization\": f\"Bearer {config['CERULEAN_API_KEY']}\"}\n",
    "response = httpx.post(predict_url, json=payload, headers=headers, timeout=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification': 3, 'confidence': 0.8743406534194946}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()['stack'][0]['features'][0]['properties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3]) tensor([0.8743])\n"
     ]
    }
   ],
   "source": [
    "print(pred_dict_thresholded_nms['labels'], pred_dict_thresholded_nms['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slickformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
